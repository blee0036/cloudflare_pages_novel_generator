#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç« èŠ‚æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…·
æ£€æŸ¥ç”Ÿæˆçš„ç« èŠ‚JSONæ–‡ä»¶æ˜¯å¦ç¬¦åˆé¢„æœŸ
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Any, Tuple
from collections import Counter

# é…ç½®
DATA_DIR = Path(__file__).parent.parent / "public" / "data"
CHAPTER_MARKERS = ["ç« ", "èŠ‚", "å›", "é›†", "ç¯‡", "å¹•", "è¯", "æ®µ", "æŠ˜", "å“"]
UPPER_MARKERS = ["å·", "éƒ¨", "å†Œ", "å­£"]
ALL_MARKERS = UPPER_MARKERS + CHAPTER_MARKERS

# æ£€æŸ¥è§„åˆ™é…ç½®
MAX_TITLE_LENGTH = 80  # æ ‡é¢˜æœ€å¤§é•¿åº¦
MAX_SENTENCE_PUNCTUATION = 3  # æ ‡é¢˜ä¸­æœ€å¤šå¥å­æ ‡ç‚¹æ•°
# å¯ç–‘æ¨¡å¼ï¼šæ£€æµ‹å¯èƒ½æ˜¯æ­£æ–‡è¯¯è¯†åˆ«ä¸ºæ ‡é¢˜çš„æƒ…å†µ
SUSPICIOUS_PATTERNS = [
    (r"^[^ç¬¬\d]*è¯´[^ï¼ï¼Ÿã€‚]*ã€‚", "æ­£æ–‡è¯­å¥ï¼ˆåŒ…å«'è¯´'å¹¶ä»¥å¥å·ç»“å°¾ï¼‰"),  # "äºŒè¯ä¸è¯´ã€‚ç›´æ¥..."
    (r"^[æ˜¯è¿™é‚£][^ç¬¬]*[äº†ç€]ã€‚", "ç–‘ä¼¼æ­£æ–‡ï¼ˆä»¥æ˜¯/è¿™/é‚£å¼€å¤´ï¼ŒåŒ…å«äº†/ç€ï¼Œä»¥å¥å·ç»“å°¾ï¼‰"),
    (r"^[^ç¬¬]*ï¼Œ[^ï¼ï¼Ÿã€‚]{0,10}[ã€‚ï¼ï¼Ÿ]", "åŒ…å«é€—å·å’Œç»“æŸæ ‡ç‚¹çš„çŸ­å¥"),
]


class ChapterChecker:
    def __init__(self, file_path: Path):
        self.file_path = file_path
        self.book_id = file_path.stem.replace("_chapters", "")
        self.data: Dict[str, Any] = {}
        self.chapters: List[Tuple[str, str, int, int, int]] = []
        self.issues: List[Dict[str, Any]] = []
        
    def load(self) -> bool:
        """åŠ è½½ç« èŠ‚æ•°æ®"""
        try:
            with open(self.file_path, "r", encoding="utf-8") as f:
                self.data = json.load(f)
            self.chapters = self.data.get("chapters", [])
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥ {self.file_path.name}: {e}")
            return False
    
    def check_merged_headings(self) -> int:
        """æ£€æŸ¥åˆå¹¶æ ‡é¢˜ï¼ˆä¸€è¡Œä¸­æœ‰å¤šä¸ªç« èŠ‚æ ‡è®°ï¼‰"""
        count = 0
        pattern = re.compile(
            r"ç¬¬\s*[\dã€‡é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+\s*[" + "".join(CHAPTER_MARKERS) + r"]"
        )
        for idx, chapter in enumerate(self.chapters, 1):
            title = chapter[1]
            matches = pattern.findall(title)
            if len(matches) > 1:
                count += 1
                self.issues.append({
                    "type": "merged_heading",
                    "severity": "high",
                    "chapter": idx,
                    "title": title,
                    "detail": f"å‘ç° {len(matches)} ä¸ªç« èŠ‚æ ‡è®°"
                })
        return count
    
    def check_title_length(self) -> int:
        """æ£€æŸ¥å¼‚å¸¸é•¿åº¦æ ‡é¢˜"""
        count = 0
        for idx, chapter in enumerate(self.chapters, 1):
            title = chapter[1]
            if len(title) > MAX_TITLE_LENGTH:
                count += 1
                self.issues.append({
                    "type": "long_title",
                    "severity": "medium",
                    "chapter": idx,
                    "title": title[:60] + "..." if len(title) > 60 else title,
                    "detail": f"æ ‡é¢˜é•¿åº¦ {len(title)} å­—ç¬¦"
                })
        return count
    
    def check_punctuation_density(self) -> int:
        """æ£€æŸ¥æ ‡é¢˜ä¸­çš„æ ‡ç‚¹å¯†åº¦"""
        count = 0
        # åªæ£€æŸ¥é€—å·ã€å¥å·ã€é¡¿å·ã€åˆ†å·ï¼ˆæ’é™¤æ„Ÿå¹å·å’Œé—®å·ï¼Œå®ƒä»¬åœ¨æ ‡é¢˜ä¸­å¾ˆå¸¸è§ï¼‰
        sentence_punct = re.compile(r"[ï¼Œã€‚ã€ï¼›]")
        for idx, chapter in enumerate(self.chapters, 1):
            title = chapter[1]
            # æ’é™¤åŒ…å«å·/éƒ¨ç­‰ä¸Šå±‚æ ‡è®°çš„æ ‡é¢˜ï¼ˆå®ƒä»¬å¯èƒ½è¾ƒé•¿ï¼‰
            has_upper_marker = any(marker in title for marker in UPPER_MARKERS)
            if has_upper_marker:
                continue
            
            # ç§»é™¤æœ«å°¾æ„Ÿå¹å·å’Œé—®å·å†æ£€æŸ¥
            title_cleaned = re.sub(r"[ï¼!ï¼Ÿ?]+$", "", title)
            matches = sentence_punct.findall(title_cleaned)
            if len(matches) > MAX_SENTENCE_PUNCTUATION:
                count += 1
                self.issues.append({
                    "type": "high_punctuation",
                    "severity": "medium",
                    "chapter": idx,
                    "title": title,
                    "detail": f"åŒ…å« {len(matches)} ä¸ªå¥å­æ ‡ç‚¹"
                })
        return count
    
    def check_suspicious_titles(self) -> int:
        """æ£€æŸ¥å¯ç–‘æ ‡é¢˜ï¼ˆå¯èƒ½æ˜¯æ­£æ–‡è¯¯è¯†åˆ«ï¼‰"""
        count = 0
        for idx, chapter in enumerate(self.chapters, 1):
            title = chapter[1]
            # ç§»é™¤å·/éƒ¨å‰ç¼€è¿›è¡Œæ£€æŸ¥
            title_without_prefix = title
            for marker in UPPER_MARKERS:
                pattern = f"ç¬¬.*?{marker}\\s+"
                title_without_prefix = re.sub(pattern, "", title_without_prefix)
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…å¯ç–‘æ¨¡å¼
            for pattern, description in SUSPICIOUS_PATTERNS:
                if re.search(pattern, title_without_prefix):
                    count += 1
                    self.issues.append({
                        "type": "suspicious_title",
                        "severity": "medium",
                        "chapter": idx,
                        "title": title,
                        "detail": description
                    })
                    break
        return count
    
    def check_duplicate_titles(self) -> int:
        """æ£€æŸ¥é‡å¤æ ‡é¢˜"""
        count = 0
        title_counts = Counter(chapter[1] for chapter in self.chapters)
        duplicates = {title: cnt for title, cnt in title_counts.items() if cnt > 1}
        
        for title, cnt in duplicates.items():
            indices = [idx for idx, ch in enumerate(self.chapters, 1) if ch[1] == title]
            count += cnt - 1  # é‡å¤æ¬¡æ•°
            self.issues.append({
                "type": "duplicate_title",
                "severity": "high",
                "chapter": indices[0],
                "title": title,
                "detail": f"é‡å¤ {cnt} æ¬¡ï¼Œå‡ºç°åœ¨ç« èŠ‚: {', '.join(map(str, indices[:5]))}"
            })
        return count
    
    def check_hierarchy_issues(self) -> int:
        """æ£€æŸ¥å±‚çº§é—®é¢˜"""
        count = 0
        # æ£€æŸ¥æ˜¯å¦æœ‰ç« èŠ‚åŒæ—¶åŒ…å«å¤šä¸ªä¸Šå±‚æ ‡è®°ï¼ˆä»…åœ¨æ ‡è®°ä½ç½®ï¼Œéæ ‡é¢˜å†…å®¹ï¼‰
        upper_marker_regex = re.compile(r"ç¬¬\s*\S+?\s*([" + "".join(UPPER_MARKERS) + r"])")
        for idx, chapter in enumerate(self.chapters, 1):
            title = chapter[1]
            # åªæ£€æŸ¥ä½œä¸ºæ ‡è®°ä½¿ç”¨çš„ä¸Šå±‚markerï¼ˆåœ¨"ç¬¬Xå·/éƒ¨"æ ¼å¼ä¸­ï¼‰
            upper_matches = upper_marker_regex.findall(title)
            if len(upper_matches) > 1:
                count += 1
                self.issues.append({
                    "type": "multiple_upper_markers",
                    "severity": "high",
                    "chapter": idx,
                    "title": title,
                    "detail": f"åŒ…å«å¤šä¸ªä¸Šå±‚æ ‡è®°: {', '.join(upper_matches)}"
                })
        
        # æ£€æŸ¥ä¸Šå±‚æ ‡è®°æ˜¯å¦åº”è¯¥åœ¨ä¸»æ ‡è®°ä¹‹å‰
        upper_marker_pattern = re.compile(r"ç¬¬.*?([" + "".join(UPPER_MARKERS) + r"])")
        primary_marker_pattern = re.compile(r"ç¬¬.*?([" + "".join(CHAPTER_MARKERS) + r"])")
        
        for idx, chapter in enumerate(self.chapters, 1):
            title = chapter[1]
            upper_match = upper_marker_pattern.search(title)
            primary_match = primary_marker_pattern.search(title)
            
            # å¦‚æœåŒæ—¶æœ‰ä¸Šå±‚å’Œä¸»æ ‡è®°ï¼Œä¸Šå±‚åº”è¯¥åœ¨å‰
            if upper_match and primary_match:
                if upper_match.start() > primary_match.start():
                    count += 1
                    self.issues.append({
                        "type": "reversed_hierarchy",
                        "severity": "high",
                        "chapter": idx,
                        "title": title,
                        "detail": f"ä¸Šå±‚æ ‡è®° '{upper_match.group(1)}' åœ¨ä¸»æ ‡è®° '{primary_match.group(1)}' ä¹‹å"
                    })
        
        return count
    
    def check_missing_markers(self) -> int:
        """æ£€æŸ¥ç¼ºå°‘ç« èŠ‚æ ‡è®°çš„æ ‡é¢˜"""
        count = 0
        special_titles = ["æ¥”å­", "åºç« ", "åºè¨€", "å¼•å­", "ç»ˆç« ", "å°¾å£°", "å°¾è®°", "åè®°", "ç•ªå¤–", "å¤–ä¼ ", "å…¨æ–‡"]
        
        for idx, chapter in enumerate(self.chapters, 1):
            title = chapter[1]
            # è·³è¿‡ç‰¹æ®Šæ ‡é¢˜
            if any(special in title for special in special_titles):
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•å·²çŸ¥æ ‡è®°
            has_marker = any(marker in title for marker in ALL_MARKERS)
            if not has_marker:
                count += 1
                self.issues.append({
                    "type": "missing_marker",
                    "severity": "medium",
                    "chapter": idx,
                    "title": title,
                    "detail": "æ ‡é¢˜ä¸­æœªå‘ç°ç« èŠ‚æ ‡è®°"
                })
        
        return count
    
    def analyze_statistics(self) -> Dict[str, Any]:
        """åˆ†æç« èŠ‚ç»Ÿè®¡ä¿¡æ¯"""
        if not self.chapters:
            return {}
        
        titles = [ch[1] for ch in self.chapters]
        lengths = [len(title) for title in titles]
        
        # ç»Ÿè®¡æ ‡è®°ä½¿ç”¨æƒ…å†µ
        marker_counts = {marker: 0 for marker in ALL_MARKERS}
        for title in titles:
            for marker in ALL_MARKERS:
                if marker in title:
                    marker_counts[marker] += 1
        
        # ç»Ÿè®¡æœ‰ä¸Šå±‚æ ‡è®°å‰ç¼€çš„ç« èŠ‚
        chapters_with_prefix = sum(1 for title in titles if any(m in title for m in UPPER_MARKERS))
        
        return {
            "total_chapters": len(self.chapters),
            "avg_title_length": sum(lengths) / len(lengths),
            "min_title_length": min(lengths),
            "max_title_length": max(lengths),
            "marker_usage": {k: v for k, v in marker_counts.items() if v > 0},
            "chapters_with_upper_prefix": chapters_with_prefix,
            "prefix_ratio": f"{chapters_with_prefix / len(self.chapters) * 100:.1f}%"
        }
    
    def run_all_checks(self) -> None:
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        if not self.load():
            return
        
        print(f"\n{'='*70}")
        print(f"ğŸ“š æ£€æŸ¥ä¹¦ç±: {self.data['book']['title']} - {self.data['book']['author']}")
        print(f"   æ–‡ä»¶: {self.file_path.name}")
        print(f"{'='*70}")
        
        # è¿è¡Œå„é¡¹æ£€æŸ¥
        checks = [
            ("åˆå¹¶æ ‡é¢˜", self.check_merged_headings),
            ("é‡å¤æ ‡é¢˜", self.check_duplicate_titles),
            ("å¼‚å¸¸é•¿åº¦", self.check_title_length),
            ("æ ‡ç‚¹å¯†åº¦", self.check_punctuation_density),
            ("å±‚çº§é—®é¢˜", self.check_hierarchy_issues),
            ("ç¼ºå°‘æ ‡è®°", self.check_missing_markers),
            ("å¯ç–‘æ ‡é¢˜", self.check_suspicious_titles),
        ]
        
        results = {}
        for name, func in checks:
            count = func()
            results[name] = count
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        stats = self.analyze_statistics()
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»ç« èŠ‚æ•°: {stats['total_chapters']}")
        print(f"   å¹³å‡æ ‡é¢˜é•¿åº¦: {stats['avg_title_length']:.1f} å­—ç¬¦")
        print(f"   æ ‡é¢˜é•¿åº¦èŒƒå›´: {stats['min_title_length']} - {stats['max_title_length']}")
        if stats['marker_usage']:
            print(f"   ä½¿ç”¨çš„æ ‡è®°: {', '.join(f'{k}({v})' for k, v in stats['marker_usage'].items())}")
        print(f"   å¸¦ä¸Šå±‚å‰ç¼€çš„ç« èŠ‚: {stats['chapters_with_upper_prefix']} ({stats['prefix_ratio']})")
        
        # è¾“å‡ºæ£€æŸ¥ç»“æœ
        print(f"\nğŸ” æ£€æŸ¥ç»“æœ:")
        total_issues = sum(results.values())
        for name, count in results.items():
            status = "âœ…" if count == 0 else "âš ï¸" if count < 5 else "âŒ"
            print(f"   {status} {name}: {count}")
        
        # è¾“å‡ºé—®é¢˜è¯¦æƒ…
        if self.issues:
            print(f"\nğŸ“‹ é—®é¢˜è¯¦æƒ… (å…± {len(self.issues)} ä¸ª):")
            # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
            severity_order = {"high": 0, "medium": 1, "low": 2}
            sorted_issues = sorted(self.issues, key=lambda x: (severity_order[x["severity"]], x["chapter"]))
            
            for issue in sorted_issues[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                severity_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}[issue["severity"]]
                print(f"   {severity_icon} ç« èŠ‚ {issue['chapter']}: {issue['type']}")
                print(f"      æ ‡é¢˜: {issue['title']}")
                print(f"      è¯´æ˜: {issue['detail']}")
            
            if len(self.issues) > 20:
                print(f"   ... è¿˜æœ‰ {len(self.issues) - 20} ä¸ªé—®é¢˜æœªæ˜¾ç¤º")
        else:
            print(f"\nâœ¨ æœªå‘ç°é—®é¢˜ï¼")
        
        # æ€»ç»“
        print(f"\n{'='*70}")
        if total_issues == 0:
            print(f"âœ… æ£€æŸ¥é€šè¿‡ï¼ç« èŠ‚æ•°æ®è´¨é‡è‰¯å¥½ã€‚")
        elif total_issues < 10:
            print(f"âš ï¸  å‘ç° {total_issues} ä¸ªé—®é¢˜ï¼Œå»ºè®®æ£€æŸ¥ã€‚")
        else:
            print(f"âŒ å‘ç° {total_issues} ä¸ªé—®é¢˜ï¼Œéœ€è¦å¤„ç†ã€‚")
        print(f"{'='*70}\n")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” ç« èŠ‚æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…·")
    print("=" * 70)
    
    # æŸ¥æ‰¾æ‰€æœ‰ç« èŠ‚æ–‡ä»¶
    chapter_files = list(DATA_DIR.glob("*_chapters.json"))
    
    if not chapter_files:
        print(f"âŒ æœªæ‰¾åˆ°ç« èŠ‚æ–‡ä»¶ï¼Œè·¯å¾„: {DATA_DIR}")
        return
    
    print(f"æ‰¾åˆ° {len(chapter_files)} ä¸ªç« èŠ‚æ–‡ä»¶\n")
    
    # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶
    all_results = []
    for file_path in sorted(chapter_files):
        checker = ChapterChecker(file_path)
        checker.run_all_checks()
        all_results.append({
            "book": checker.data.get("book", {}).get("title", "æœªçŸ¥"),
            "total_issues": len(checker.issues),
            "chapters": len(checker.chapters)
        })
    
    # è¾“å‡ºæ€»ä½“æ±‡æ€»
    if len(all_results) > 1:
        print(f"\n{'='*70}")
        print("ğŸ“Š æ€»ä½“æ±‡æ€»")
        print(f"{'='*70}")
        total_chapters = sum(r["chapters"] for r in all_results)
        total_issues = sum(r["total_issues"] for r in all_results)
        print(f"æ€»ä¹¦ç±æ•°: {len(all_results)}")
        print(f"æ€»ç« èŠ‚æ•°: {total_chapters}")
        print(f"æ€»é—®é¢˜æ•°: {total_issues}")
        print(f"å¹³å‡è´¨é‡: {(1 - total_issues / max(total_chapters, 1)) * 100:.1f}%")
        print(f"{'='*70}\n")


if __name__ == "__main__":
    main()
